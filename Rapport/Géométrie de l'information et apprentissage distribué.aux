\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode`:\active
\catcode`;\active
\catcode`!\active
\catcode`?\active
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{french}
\@writefile{toc}{\select@language{french}}
\@writefile{lof}{\select@language{french}}
\@writefile{lot}{\select@language{french}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Neurone grossi 63 fois, image de Kieran Boyle}}{1}{figure.1}}
\newlabel{fig:Neurone}{{1}{1}{Neurone grossi 63 fois, image de Kieran Boyle}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Point de vue g\IeC {\'e}om\IeC {\'e}trique en statistique}{3}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}G\IeC {\'e}om\IeC {\'e}trie de l'information}{3}{subsection.1.1}}
\citation{Amari1994}
\citation{Amari1998}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Algorithme de descente de gradient naturel}{4}{subsection.1.2}}
\newlabel{ellipse}{{1.2}{4}{Algorithme de descente de gradient naturel}{subsection.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces En bleu, le gradient euclidien, et en rouge le gradient corrig\IeC {\'e}. En un point o\IeC {\`u} l'ellipse est tr\IeC {\`e}s courb\IeC {\'e}e, le gradient riemannien donne une meilleure direction de descente.}}{4}{figure.2}}
\citation{Ollivier}
\citation{Ollivier}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}M\IeC {\'e}triques invariantes}{6}{subsection.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}R\IeC {\'e}seau de neurones}{6}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Pr\IeC {\'e}sentation}{6}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neurones binaires et algorithme du "perceptron convergence procedure"}{8}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Neurones lin\IeC {\'e}aires ou filtres lin\IeC {\'e}aires}{9}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}La surface d'erreur du neurone lin\IeC {\'e}aire}{10}{subsubsection.2.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces La forme typique d'une surface d'erreur quadratique.}}{11}{figure.3}}
\newlabel{fig:Surface}{{3}{11}{La forme typique d'une surface d'erreur quadratique}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Les lignes de niveau d'une surface d'erreur quadratique sont bien des ellipses. }}{11}{figure.4}}
\newlabel{fig:level}{{4}{11}{Les lignes de niveau d'une surface d'erreur quadratique sont bien des ellipses}{figure.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Pourquoi plusieurs couches?}{12}{subsubsection.2.3.2}}
\newlabel{XOR}{{2.3.2}{12}{Pourquoi plusieurs couches?}{subsubsection.2.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Repr\IeC {\'e}sentation graphique du <<ou exclusif>>.}}{12}{figure.5}}
\newlabel{RN2}{{2.3.2}{12}{Pourquoi plusieurs couches?}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces R\IeC {\'e}seau de neurones \IeC {\`a} deux couches.}}{12}{figure.6}}
\newlabel{Dessin}{{2.3.2}{13}{Pourquoi plusieurs couches?}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces S\IeC {\'e}paration non lin\IeC {\'e}aire}}{13}{figure.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Exp\IeC {\'e}riences autour du Xor}{13}{subsubsection.2.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Repr\IeC {\'e}sentation d'un tirage de xor al\IeC {\'e}atoire}}{14}{figure.8}}
\newlabel{fig:xoralea}{{8}{14}{Représentation d'un tirage de xor aléatoire}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Reconnaissance par un svm \textbf  {lin\IeC {\'e}aire} du xor}}{16}{figure.9}}
\newlabel{fig:svmlinxor}{{9}{16}{Reconnaissance par un svm \textbf {linéaire} du xor}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Reconnaissance par un svm avec un noyau \textbf  {de degr\IeC {\'e} $2$} du xor}}{17}{figure.10}}
\newlabel{fig:svmpolydot}{{10}{17}{Reconnaissance par un svm avec un noyau \textbf {de degré $2$} du xor}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Reconnaissance par un r\IeC {\'e}seau neuronal du xor}}{18}{figure.11}}
\newlabel{fig:nnxor}{{11}{18}{Reconnaissance par un réseau neuronal du xor}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Neurones logistiques}{19}{subsection.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Algorithme de r\IeC {\'e}tropropagation}{19}{subsection.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}}{20}{subsection.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Point de vue g\IeC {\'e}om\IeC {\'e}trique}{21}{subsection.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Machines de Boltzmann}{21}{subsection.2.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}Introduction}{21}{subsubsection.2.8.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}Dynamique stochastique d'une machine de Boltzmann}{21}{subsubsection.2.8.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.3}Learning dans les machines de Boltzmann}{23}{subsubsection.2.8.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Restricted Boltzmann machines}{23}{subsection.2.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.1}Introduction}{23}{subsubsection.2.9.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.2}Deep Learning \IeC {\`a} l'aide de RBM}{24}{subsubsection.2.9.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.9.3}Pr\IeC {\'e}cisions sur l'algorithme de Contrastive divergence (not\IeC {\'e} CD-1)}{24}{subsubsection.2.9.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Deep Belief Networks}{25}{subsection.2.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11}Multilayer Neural Network}{27}{subsection.2.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.12}Cas du perceptron}{28}{subsection.2.12}}
\bibstyle{plain}
\bibdata{biblio}
\bibcite{Amari1994}{1}
\bibcite{Amari1998}{2}
\bibcite{Ollivier}{3}
\bibcite{Amari}{4}
\citation{*}
\@writefile{toc}{\contentsline {section}{\numberline {3}Application \IeC {\`a} la reconnaissance de caract\IeC {\`e}res manuscrits}{29}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Appendice}{29}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}G\IeC {\'e}om\IeC {\'e}trie diff\IeC {\'e}rentielle}{29}{subsection.4.1}}
