\select@language {french}
\contentsline {section}{\numberline {1}R\IeC {\'e}seau de neurones}{3}{section.1}
\contentsline {subsection}{\numberline {1.1}Pr\IeC {\'e}sentation}{3}{subsection.1.1}
\contentsline {subsection}{\numberline {1.2}Neurones binaires et algorithme du "perceptron convergence procedure"}{5}{subsection.1.2}
\contentsline {subsection}{\numberline {1.3}Neurones lin\IeC {\'e}aires ou filtres lin\IeC {\'e}aires}{6}{subsection.1.3}
\contentsline {subsubsection}{\numberline {1.3.1}La surface d'erreur du neurone lin\IeC {\'e}aire}{6}{subsubsection.1.3.1}
\contentsline {subsubsection}{\numberline {1.3.2}Pourquoi plusieurs couches?}{8}{subsubsection.1.3.2}
\contentsline {subsubsection}{\numberline {1.3.3}Exp\IeC {\'e}riences autour du Xor}{10}{subsubsection.1.3.3}
\contentsline {subsection}{\numberline {1.4}Neurones logistiques}{16}{subsection.1.4}
\contentsline {subsection}{\numberline {1.5}Algorithme de r\IeC {\'e}tropropagation}{16}{subsection.1.5}
\contentsline {subsection}{\numberline {1.6}Point de vue g\IeC {\'e}om\IeC {\'e}trique}{17}{subsection.1.6}
\contentsline {subsection}{\numberline {1.7}Machines de Boltzmann}{17}{subsection.1.7}
\contentsline {subsubsection}{\numberline {1.7.1}Introduction}{17}{subsubsection.1.7.1}
\contentsline {subsubsection}{\numberline {1.7.2}Dynamique stochastique d'une machine de Boltzmann}{18}{subsubsection.1.7.2}
\contentsline {subsubsection}{\numberline {1.7.3}Learning dans les machines de Boltzmann}{19}{subsubsection.1.7.3}
\contentsline {subsection}{\numberline {1.8}Restricted Boltzmann machines}{20}{subsection.1.8}
\contentsline {subsubsection}{\numberline {1.8.1}Introduction}{20}{subsubsection.1.8.1}
\contentsline {subsubsection}{\numberline {1.8.2}Deep Learning \IeC {\`a} l'aide de RBM}{20}{subsubsection.1.8.2}
\contentsline {subsubsection}{\numberline {1.8.3}Pr\IeC {\'e}cisions sur l'algorithme de Contrastive divergence (not\IeC {\'e} CD-1)}{21}{subsubsection.1.8.3}
\contentsline {subsection}{\numberline {1.9}Deep Belief Networks}{22}{subsection.1.9}
\contentsline {subsection}{\numberline {1.10}Multilayer Neural Network}{24}{subsection.1.10}
\contentsline {subsection}{\numberline {1.11}Cas du perceptron}{25}{subsection.1.11}
\contentsline {section}{\numberline {2}Point de vue g\IeC {\'e}om\IeC {\'e}trique en statistique}{26}{section.2}
\contentsline {subsection}{\numberline {2.1}G\IeC {\'e}om\IeC {\'e}trie de l'information}{26}{subsection.2.1}
\contentsline {subsection}{\numberline {2.2}Algorithme de descente de gradient naturel}{27}{subsection.2.2}
\contentsline {subsection}{\numberline {2.3}M\IeC {\'e}triques invariantes}{29}{subsection.2.3}
\contentsline {subsection}{\numberline {2.4}M\IeC {\'e}triques de Fisher pour les r\IeC {\'e}saux de neurones}{30}{subsection.2.4}
\contentsline {subsection}{\numberline {2.5}M\IeC {\'e}thodes d'apprentissage profond test\IeC {\'e}es sur MNIST}{30}{subsection.2.5}
\contentsline {section}{\numberline {3}Comparaison entre descente de gradient euclidienne et riemannienne sur l'exemple du XOR al\IeC {\'e}atoire}{32}{section.3}
\contentsline {subsection}{\numberline {3.1}Mod\IeC {\`e}le}{32}{subsection.3.1}
\contentsline {subsection}{\numberline {3.2}Proc\IeC {\'e}dure de test}{33}{subsection.3.2}
\contentsline {subsection}{\numberline {3.3}R\IeC {\'e}sultats}{34}{subsection.3.3}
