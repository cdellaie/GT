\select@language {french}
\contentsline {section}{\numberline {1}R\IeC {\'e}seau de neurones}{3}{section.1}
\contentsline {subsection}{\numberline {1.1}Pr\IeC {\'e}sentation}{3}{subsection.1.1}
\contentsline {subsection}{\numberline {1.2}Neurones binaires et algorithme du "perceptron convergence procedure"}{5}{subsection.1.2}
\contentsline {subsection}{\numberline {1.3}Neurones lin\IeC {\'e}aires ou filtres lin\IeC {\'e}aires}{6}{subsection.1.3}
\contentsline {subsubsection}{\numberline {1.3.1}La surface d'erreur du neurone lin\IeC {\'e}aire}{6}{subsubsection.1.3.1}
\contentsline {subsubsection}{\numberline {1.3.2}Pourquoi plusieurs couches?}{9}{subsubsection.1.3.2}
\contentsline {subsubsection}{\numberline {1.3.3}Exp\IeC {\'e}riences autour du Xor}{11}{subsubsection.1.3.3}
\contentsline {subsection}{\numberline {1.4}Neurones logistiques}{17}{subsection.1.4}
\contentsline {subsection}{\numberline {1.5}Algorithme de r\IeC {\'e}tropropagation}{17}{subsection.1.5}
\contentsline {subsection}{\numberline {1.6}}{18}{subsection.1.6}
\contentsline {subsection}{\numberline {1.7}Point de vue g\IeC {\'e}om\IeC {\'e}trique}{19}{subsection.1.7}
\contentsline {subsection}{\numberline {1.8}Machines de Boltzmann}{19}{subsection.1.8}
\contentsline {subsubsection}{\numberline {1.8.1}Introduction}{19}{subsubsection.1.8.1}
\contentsline {subsubsection}{\numberline {1.8.2}Dynamique stochastique d'une machine de Boltzmann}{19}{subsubsection.1.8.2}
\contentsline {subsubsection}{\numberline {1.8.3}Learning dans les machines de Boltzmann}{21}{subsubsection.1.8.3}
\contentsline {subsection}{\numberline {1.9}Restricted Boltzmann machines}{21}{subsection.1.9}
\contentsline {subsubsection}{\numberline {1.9.1}Introduction}{21}{subsubsection.1.9.1}
\contentsline {subsubsection}{\numberline {1.9.2}Deep Learning \IeC {\`a} l'aide de RBM}{22}{subsubsection.1.9.2}
\contentsline {subsubsection}{\numberline {1.9.3}Pr\IeC {\'e}cisions sur l'algorithme de Contrastive divergence (not\IeC {\'e} CD-1)}{22}{subsubsection.1.9.3}
\contentsline {subsection}{\numberline {1.10}Deep Belief Networks}{23}{subsection.1.10}
\contentsline {subsection}{\numberline {1.11}Multilayer Neural Network}{25}{subsection.1.11}
\contentsline {subsection}{\numberline {1.12}Cas du perceptron}{26}{subsection.1.12}
\contentsline {section}{\numberline {2}Point de vue g\IeC {\'e}om\IeC {\'e}trique en statistique}{27}{section.2}
\contentsline {subsection}{\numberline {2.1}G\IeC {\'e}om\IeC {\'e}trie de l'information}{27}{subsection.2.1}
\contentsline {subsection}{\numberline {2.2}Algorithme de descente de gradient naturel}{28}{subsection.2.2}
\contentsline {subsection}{\numberline {2.3}M\IeC {\'e}triques invariantes}{30}{subsection.2.3}
\contentsline {subsection}{\numberline {2.4}M\IeC {\'e}triques de Fisher pour les r\IeC {\'e}saux de neurones}{31}{subsection.2.4}
\contentsline {subsection}{\numberline {2.5}Application \IeC {\`a} la reconnaissance de caract\IeC {\`e}res manuscrits}{31}{subsection.2.5}
\contentsline {section}{\numberline {3}Comparaison de la descente de gradient Euclidienne et de celle Riemanienne sur l'exemple du XOR al\IeC {\'e}atoire}{32}{section.3}
\contentsline {subsection}{\numberline {3.1}Mod\IeC {\`e}le}{32}{subsection.3.1}
\contentsline {subsection}{\numberline {3.2}Proc\IeC {\'e}dure de test}{33}{subsection.3.2}
\contentsline {subsection}{\numberline {3.3}R\IeC {\'e}sultats}{33}{subsection.3.3}
\contentsline {section}{\numberline {4}Appendice}{34}{section.4}
\contentsline {subsection}{\numberline {4.1}G\IeC {\'e}om\IeC {\'e}trie diff\IeC {\'e}rentielle}{34}{subsection.4.1}
