svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
svp <- ksvm(x,y,type="C-svc",kernel="vanilladot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
library("neuralnet")
data=cbind(x,y)
net.xor <- neuralnet(y~u+v,data, hidden=10,act.fct="logistic", threshold=0.01)
plot(net.xor)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
svp <- ksvm(x,y,type="C-svc",kernel="vanilladot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
plot(net.xor)
test<-  matrix(c(1,1,-1,1,1,-1,-1,-1),ncol=2,byrow=TRUE)
net.results <-  compute(net.xor,as.data.frame(test))
plot(net.results)
plot(net.results$net.result)
print(net.results)
View(test)
View(test)
View(test)
View(test)
prediction(net.xor)
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel="vanilladot")
plot(svp,data=x)
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
u <- 1*(U<0.5)*(1*(V<0.5)*(s*X+1)+1*(V>0.5)*(s*X-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*X-1)+1*(W>0.5)*(s*X+1))
v <- 1*(U<0.5)*(1*(V<0.5)*(s*Y+1)+1*(V>0.5)*(s*Y-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*Y+1)+1*(W>0.5)*(s*Y-1))
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(U^2+v^2<1)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
u <- 1*(U<0.5)*(1*(V<0.5)*(s*X+1)+1*(V>0.5)*(s*X-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*X-1)+1*(W>0.5)*(s*X+1))
v <- 1*(U<0.5)*(1*(V<0.5)*(s*Y+1)+1*(V>0.5)*(s*Y-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*Y+1)+1*(W>0.5)*(s*Y-1))
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*((U^2+v^2)<1)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
1*(0.5*05<1)
1*(0.5*5<1)
(0.5*5<1)
1*(0.5*0.5<1)
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
u <- 1*(U<0.5)*(1*(V<0.5)*(s*X+1)+1*(V>0.5)*(s*X-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*X-1)+1*(W>0.5)*(s*X+1))
v <- 1*(U<0.5)*(1*(V<0.5)*(s*Y+1)+1*(V>0.5)*(s*Y-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*Y+1)+1*(W>0.5)*(s*Y-1))
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(U*u+v*v<1)
1*(0.5*0.5<1)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
1*(0.5*0.5+0.5*0.5<1)
1*(2*0.5+0.5*0.5<1)
1*(2*2+0.5*0.5<1)
view(u)
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(U*u+v*v<1)
1*(2*2+0.5*0.5<1)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(U*u+v*v<1)
1*(2*2+0.5*0.5<1)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<1)
1*(2*2+0.5*0.5<1)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<1)
1*(2*2+0.5*0.5<1)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
library(kernlab)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<1)
1*(2*2+0.5*0.5<2)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
library(kernlab)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<1)
1*(2*2+0.5*0.5<2)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<2)
1*(2*2+0.5*0.5<2)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
svp <- ksvm(x,y,type="C-svc",kernel="vanilladot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
library("neuralnet")
data=cbind(x,y)
net.xor <- neuralnet(y~u+v,data, hidden=10,act.fct="logistic", threshold=0.01)
print(net.xor)
plot(net.xor)
test<-  matrix(c(1,1,-1,1,1,-1,-1,-1),ncol=2,byrow=TRUE)
net.results <-  compute(net.xor,as.data.frame(test))
print(net.results$net.result)
install.packages("kernlab")
install.packages("neuralnet")
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
u <- 1*(U<0.5)*(1*(V<0.5)*(s*X+1)+1*(V>0.5)*(s*X-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*X-1)+1*(W>0.5)*(s*X+1))
v <- 1*(U<0.5)*(1*(V<0.5)*(s*Y+1)+1*(V>0.5)*(s*Y-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*Y+1)+1*(W>0.5)*(s*Y-1))
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(U<0.5)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
#méthodes par noyaux
library(kernlab)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
svp <- ksvm(x,y,type="C-svc",kernel="vanilladot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
#RN
#Régression logistique sur le xor aléatoire
library("neuralnet")
data=cbind(x,y)
net.xor <- neuralnet(y~u+v,data, hidden=10,act.fct="logistic", threshold=0.01)
#install.packages("kernlab")
#install.packages("neuralnet")
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
u <- 1*(U<0.5)*(1*(V<0.5)*(s*X+1)+1*(V>0.5)*(s*X-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*X-1)+1*(W>0.5)*(s*X+1))
v <- 1*(U<0.5)*(1*(V<0.5)*(s*Y+1)+1*(V>0.5)*(s*Y-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*Y+1)+1*(W>0.5)*(s*Y-1))
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(U<0.5)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
#méthodes par noyaux
library(kernlab)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
svp <- ksvm(x,y,type="C-svc",kernel="vanilladot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
#RN
#Régression logistique sur le xor aléatoire
library("neuralnet")
data=cbind(x,y)
net.xor <- neuralnet(y~u+v,data, hidden=10,act.fct="logistic", threshold=0.01)
print(net.xor)
plot(net.xor)
prediction(net.xor)
#testons le RN sur des exemples
test<-  matrix(c(1,1,-1,1,1,-1,-1,-1),ncol=2,byrow=TRUE)
net.results <-  compute(net.xor,as.data.frame(test))
ls(net.results)
print(net.results$net.result)
test
print(net.results)
plot(net.results$net.result)
help(ls)
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<2)
1*(2*2+0.5*0.5<2)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
print(net.xor)
data=cbind(x,y)
net.circle <- neuralnet(y~u+v,data, hidden=10,act.fct="logistic", threshold=0.01)
net.circle <- neuralnet(y~u+v,data, hidden=10,act.fct="logistic", threshold=0.01)
prediction(net.circle)
print(net.circle)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
print[svp$error]
print[svp@error]
plot(svp,data=x)
test<-  matrix(c(1,1,-1,1,1,-1,-1,-1),ncol=2,byrow=TRUE)
net.resultsc <-  compute(net.circle,as.data.frame(test))
print(net.resultsc$net.result)
test<-  matrix(c(0,0,-1,1,1,-1,-1,-1),ncol=2,byrow=TRUE)
net.resultsc <-  compute(net.circle,as.data.frame(test))
print(net.resultsc$net.result)
test<-  matrix(c(0,0,-1/2,1/2,1,-1,-1,-1),ncol=2,byrow=TRUE)
net.resultsc <-  compute(net.circle,as.data.frame(test))
ls(net.resultsc)
print(net.resultsc$net.result)
test<-  matrix(c(0,0,-1/2,sqrt(3)/2,1,-1,-1,-1),ncol=2,byrow=TRUE)
net.resultsc <-  compute(net.circle,as.data.frame(test))
ls(net.resultsc)
print(net.resultsc$net.result)
svp <- ksvm(x,y,type="C-svc",kernel="vanilladot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
Ktest<-as.kernelMatrix(crossprod(t(xtest),t(x[SVindex(svp)])))
Ktest<-as.kernelMatrix(crossprod(t(test),t(x[SVindex(svp)])))
SVindex(svp)
x[SVindex(svp)]
dim(x)
x1<-cbind(w,z)
Ktest<-as.kernelMatrix(crossprod(t(x1),t(x[SVindex(svp)])))
w <- runif(n,0,1)
z <- runif(n,0,1)
x1<-cbind(w,z)
Ktest<-as.kernelMatrix(crossprod(t(x1),t(x[SVindex(svp)])))
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
u <- runif(n,0,1)
v <- runif(n,0,1)
w <- runif(n,0,1)
z <- runif(n,0,1)
x <- rnorm(n,0,1)
y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<2)
1*(2*2+0.5*0.5<2)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='points dans le cercle')
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
u <- runif(n,0,1)
v <- runif(n,0,1)
w <- runif(n,0,1)
z <- runif(n,0,1)
x <- rnorm(n,0,1)
y <- rnorm(n,0,1)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<1)
1*(2*2+0.5*0.5<2)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='points dans le cercle')
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
help(runif)
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
u <- runif(n,-1,1)
v <- runif(n,-1,1)
w <- runif(n,0,1)
z <- runif(n,0,1)
x <- rnorm(n,0,1)
y <- rnorm(n,0,1)
help(runif)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<1)
1*(2*2+0.5*0.5<2)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='points dans le cercle')
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
u <- runif(n,-1.5,1.5)
v <- runif(n,-1.5,1.5)
w <- runif(n,0,1)
z <- runif(n,0,1)
x <- rnorm(n,0,1)
y <- rnorm(n,0,1)
help(runif)
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(u*u+v*v<1)
1*(2*2+0.5*0.5<2)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='points dans le cercle')
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
svp <- ksvm(x,y,type="C-svc",kernel="vanilladot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
#install.packages("kernlab")
#install.packages("neuralnet")
#xor aléatoire
n=1000
s=0.4
#Construction d'un mélange de gaussiennes
U <- runif(n,0,1)
V <- runif(n,0,1)
W <- runif(n,0,1)
X <- rnorm(n,0,1)
Y <- rnorm(n,0,1)
u <- 1*(U<0.5)*(1*(V<0.5)*(s*X+1)+1*(V>0.5)*(s*X-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*X-1)+1*(W>0.5)*(s*X+1))
v <- 1*(U<0.5)*(1*(V<0.5)*(s*Y+1)+1*(V>0.5)*(s*Y-1)) +
1*(U>0.5)*(1*(W<0.5)*(s*Y+1)+1*(W>0.5)*(s*Y-1))
x=cbind(u,v)
colnames(x)=c("Input","Output")
y <- 1*(U<0.5)
couleur <- rep('red',n)
couleur[y==1]<-'blue'
plot(u,v, col=couleur)
title(main='Version aléatoire du Xor')
svp <- ksvm(x,y,type="C-svc",kernel="vanilladot")
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
svp <- ksvm(x,y,type="C-svc",kernel=polydot(degree=2))
plot(svp,data=x)
svp <- ksvm(x,y,type="C-svc",kernel="rbfdot")
plot(svp,data=x)
title("SVM classification plot")
